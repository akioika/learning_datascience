{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http 通信用ライブラリ\n",
    "from requests_html import HTMLSession\n",
    "# html 処理用ライブラリ\n",
    "from bs4 import BeautifulSoup\n",
    "# 正規表現用ライブラリ\n",
    "import re\n",
    "\n",
    "\n",
    "# ログインするサイトの場合、cookie の処理が必要となるが\n",
    "# session オブジェクトで操作するとその辺の面倒さがなくなってお手軽\n",
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニュース一覧を取得する\n",
    "base_url = \"https://www.msn.com\"\n",
    "\n",
    "# MSN のニュースのトップにアクセスします。\n",
    "# response オブジェクトの詳細は https://requests-docs-ja.readthedocs.io/en/latest/user/quickstart/#id3 に記載されています\n",
    "response = session.get(base_url + \"/ja-jp/news\")\n",
    "print(response.status_code)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html をパースする\n",
    "bs = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "# news 一覧を作成\n",
    "news_list = []\n",
    "# すべての A タグを取得し、ループで処理\n",
    "for a_tag in bs.find_all(\"a\"):\n",
    "    # 遷移先を取得\n",
    "    href = a_tag.get(\"href\")\n",
    "    # 記事のタイトルを取得 ( 不要な空白と制御文字を削除 )\n",
    "    title = a_tag.get_text().strip().strip('\\r\\n\\t')\n",
    "    # 記事の URL だった場合リストに追加\n",
    "    if re.match(\"/ja-jp/news/[^/]*/.*\" , href) :\n",
    "        news_list.append({\"href\":href, \"title\":title})\n",
    "\n",
    "print(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリを作成するため、ライブラリを読み込む\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "dir = \"news\"\n",
    "\n",
    "if not os.path.isdir(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "# 記事本文を取得しファイルに書き込む\n",
    "for dict in news_list:\n",
    "    response = session.get(base_url + dict[\"href\"])\n",
    "    bs = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # title タグからタイトルを取得\n",
    "    title = bs.title.get_text()\n",
    "    # 記事の公開日時が yyyy-MM-ddThh:mm:ss.000Z なので数字のみにする\n",
    "    datetime = bs.select(\"time\")[0].get(\"datetime\").translate(str.maketrans(\"\", \"\", \"-T:.Z\"))\n",
    "    # タイトルから禁則文字を除いてファイル名にする\n",
    "    path = dir+\"/\"+title.translate(str.maketrans(\"\", \"\", \" 　¥\\/:*?\\\"<>|.\"))+\"_\"+datetime+\".txt\"\n",
    "    with open(path, mode='w') as f:\n",
    "        # 本文を書き込む\n",
    "        for p in bs.select(\"section .articlebody p\"):\n",
    "            f.write(p.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
